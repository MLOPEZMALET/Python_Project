{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "##generelise here\n",
    "with open('test.txt','r',encoding='utf-8') as corpus:\n",
    "    co=corpus.readlines()\n",
    "    dic=[]\n",
    "    for e in co:\n",
    "        e.split('\\n')\n",
    "        dic.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2=[]\n",
    "for e in co:\n",
    "    for i in e.replace('\\n','').replace('?','').replace('!','').replace('.','').replace('’','').replace(',','').split():\n",
    "        dic2.append(i)\n",
    "#si on est interessé au niveau des phrases\n",
    "dicc=[[e.split()]for e in dic]\n",
    "dic3=[]\n",
    "for e in co:\n",
    "    for i in e.split():\n",
    "        dic3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    new = re.sub(r'[^\\w\\s]','',text)\n",
    "    liste=  new.split()\n",
    "    return liste\n",
    "def frequency(liste):\n",
    "#literelement: compte pour moi nombre d'occurence de chauque mot dans la liste pour chauque element de liste\n",
    "    liste_of_frequence= [liste.count(w) for w in liste]\n",
    "#les valeurs seront les nombres d'occurences dans le deuxieme liste(liste_of_frequence)\n",
    "    dictionary = dict(zip(liste,liste_of_frequence))\n",
    "#print(\"in form of a dictionary:\")\n",
    "#print(dictionary)\n",
    "#dans une celule de liste insertons clés et valeur pour chaque clés et valeur de diccionaire (methode .items() permet acceder en même temps aux clés et valeurs)\n",
    "    list_key_value = [ [k,v] for v, k in dictionary.items() ]\n",
    "#print(\"in form of a list:\")\n",
    "#print(list_key_value)\n",
    "    r=input('par ordre croissant?yes/no ')\n",
    "    if r=='yes':\n",
    "        for w in sorted(dictionary, key=dictionary.get, reverse=False):\n",
    "            print (w, dictionary[w])\n",
    "    elif r=='no':\n",
    "        for w in sorted(dictionary, key=dictionary.get, reverse=True):\n",
    "            print (w, dictionary[w])\n",
    "    else:\n",
    "        print('bad answer')\n",
    "#juste le methode sorted. en fait on peut comme ici n'indiquer pas reverse quand on a beaoin d;ordre decroissant parce que il est par defaut\n",
    "    list_croissant= sorted(list_key_value)\n",
    "    #print (list_croissant)\n",
    "    list_descroissant= sorted(list_key_value,reverse=True)\n",
    "    #print(list_descroissant)\n",
    "#verifies if pattern is correct\n",
    "def verify(inp):\n",
    "    spacyliste=['ADJ','NOUN','VERB','ADP','ADV','AUX','CCONJ','DET','PRON','PROPN','NUM','SCONJ']\n",
    "    if len(inp)>0:\n",
    "        if inp.isupper():\n",
    "            for e in inp.split():\n",
    "                if e in spacyliste:\n",
    "                    return inp\n",
    "                else:\n",
    "                    NError = ValueError('pos not from the list')\n",
    "                    raise NError\n",
    "        else:\n",
    "            NError = ValueError('in majiscule pls')\n",
    "            raise NError\n",
    "    else:\n",
    "        NError = ValueError('no pattern')\n",
    "        raise NError\n",
    "#gives the pattern \n",
    "def posstats(doc):\n",
    "    t=[ word.pos_ for word in doc]\n",
    "    liste_of_frequence= [t.count(e) for e in t]\n",
    "#les valeurs seront les nombres d'occurences dans le deuxieme liste(liste_of_frequence)\n",
    "    dictionary = dict(zip(t,liste_of_frequence))\n",
    "    list_key_value = [ [k,v] for v, k in dictionary.items() ]\n",
    "    #print(\"in form of a list:\")\n",
    "    #print(list_key_value)\n",
    "    for w in sorted(dictionary, key=dictionary.get, reverse=True):\n",
    "        print (w, dictionary[w])\n",
    "def specificity(text):\n",
    "    import math\n",
    "    import sys\n",
    "    inp=input('which document?')\n",
    "    sys.float_info.max\n",
    "    ltotal=len(text)\n",
    "    r=text.split('***')\n",
    "    l=len(r)\n",
    "    print('there are',l,'documents in your corpus ')\n",
    "    lpartie=len(r[int(inp)-1])\n",
    "    terme=input('which word? ')\n",
    "    if terme in text:\n",
    "        freqdanspartie=r[0].count(terme)\n",
    "        freqtotal=text.count(terme)\n",
    "        s=((math.factorial(ltotal-freqtotal)//(math.factorial(lpartie-freqdanspartie)*math.factorial((ltotal-freqtotal)-(lpartie-freqdanspartie))))*(math.factorial(freqtotal)//(math.factorial(freqdanspartie)*math.factorial(freqtotal-freqdanspartie))))//(math.factorial(ltotal)//(math.factorial(lpartie)*math.factorial(ltotal-lpartie)))\n",
    "        print(terme,'-',s)\n",
    "    else:\n",
    "        print('no such word in the corpus')\n",
    "def patterngiver(doc):\n",
    "    t=[(word.text, word.pos_) for word in doc]\n",
    "    inp=input(\"GIVE ME A PATTERN in MAJISCULE FROM THIS LISTE, from1 to 4 POS TAGs\")\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    l3=[]\n",
    "    l4=[]\n",
    "    if verify(inp)==inp:\n",
    "        pattern=inp.split()       \n",
    "        for e in range(len(t)-1):\n",
    "            if len(pattern)==1:\n",
    "                if pattern[0]in t[e]:\n",
    "                    l1.append(t[e][0])\n",
    "                    print(t[e])\n",
    "                    print(t[e][0])\n",
    "            elif len(pattern)==2:\n",
    "                if pattern[0] in t[e] and pattern[1] in t[e+1]:\n",
    "                    l2.append([t[e][0],t[e+1][0]])\n",
    "                    print (t[e],\"-\",t[e+1])\n",
    "                    print(t[e][0],t[e+1][0])\n",
    "            elif len(pattern)==3:\n",
    "                if pattern[0] in t[e] and pattern[1] in t[e+1] and pattern[2] in t[e+2]:\n",
    "                    l3.append([t[e][0],t[e+1][0],t[e+2][0]])\n",
    "                    print (t[e],\"-\",t[e+1],t[e+2])\n",
    "                    print(t[e][0],t[e+1][0],t[e+2][0])\n",
    "            elif len(pattern)==4:\n",
    "                if pattern[0] in t[e] and pattern[1] in t[e+1] and pattern[2] in t[e+2] and pattern[3] in t[e+3]:\n",
    "                    l4.append([t[e][0],t[e+1][0],t[e+2][0],t[e+3][0]])\n",
    "                    print (t[e],\"-\",t[e+1],\"-\",t[e+2],\"-\",t[e+3])\n",
    "                    print(t[e][0],t[e+1][0],t[e+2][0],t[e+3][0])\n",
    "        \n",
    "        print(len(l1+l2+l3+l4))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show frequencies v\n",
      "show patterns v\n",
      "show ponctuations stats v\n",
      "show statistique de parties de discours v\n",
      "specificity of the word: yes\n",
      "which document?2\n",
      "there are 2 documents in your corpus \n",
      "which word? très\n",
      "très - 0\n"
     ]
    }
   ],
   "source": [
    "text=' '.join(dic2)\n",
    "###for pos\n",
    "doc = nlp(text)\n",
    "###\n",
    "if input('show frequencies ')=='yes':\n",
    "    motvidesquestion=input('on consiedere les mots vides?yes/no ')\n",
    "    if 'no' in motvidesquestion:\n",
    "        listvide=open('stopwords.txt','r',encoding='utf-8')\n",
    "        lv=listvide.readlines()\n",
    "        dicvide=[]\n",
    "        for e in lv:\n",
    "            dicvide.append(e.replace('\\n','').replace('\\t',''))\n",
    "        liste2=tokenizer(text)\n",
    "        #lenght totale\n",
    "        print(len(liste2))\n",
    "        liste4=[e for e in liste2 if e not in dicvide]\n",
    "        #combien de mots vide?\n",
    "        print(len(liste2)-len(liste4))\n",
    "        #lenght sans mots vides\n",
    "        print(len(liste4))\n",
    "        frequency(liste4)\n",
    "    elif 'yes' in motvidesquestion:\n",
    "        liste2=tokenizer(text)\n",
    "        frequency(liste2)\n",
    "elif input('show patterns ')=='yes':\n",
    "        patterngiver(doc)\n",
    "elif input('show ponctuations stats ')=='yes':\n",
    "    cptinterog=0\n",
    "    for e in dicc:\n",
    "        for i in e:\n",
    "            if '?' in i:\n",
    "                cptinterog+=1\n",
    "    print(cptinterog,\"- ?\")\n",
    "    #combien de phrases exclamatives?\n",
    "    cptex=0\n",
    "    for e in dic3:\n",
    "        for i in e:\n",
    "            if '!' in i:\n",
    "                cptex+=1\n",
    "    print(cptex,\"- !\")\n",
    "    #combien de phrases avec ...?\n",
    "    cptpts=0\n",
    "    for e in dic3:\n",
    "        if '...' in e:\n",
    "            cptpts+=1\n",
    "    print(cptpts,\"- ...\")\n",
    "elif input('show statistique de parties de discours ')=='yes':\n",
    "    posstats(doc)\n",
    "elif input('specificity of the word: ')=='yes':\n",
    "    specificity(text)\n",
    "else:\n",
    "    print('write it correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "##gives liste of words poatags and syntax rol\n",
    "for token in doc:\n",
    "    \n",
    "    print(token.text, token.pos_, token.dep_)\n",
    "#print([(word.text, word.pos_) for word in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
